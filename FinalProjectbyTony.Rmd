---
title: "Final Project"
author: "Shane Taylor shanemt2@illinois.edu; Zhouning Ma zm11@illinois.edu; Kevin Mackie kevindm2@illinois.edu"
date: "7/28/2019"
output: html_document
---

# Group members
- Shane Taylor shanemt2@illinois.edu 
- Zhouning Ma zm11@illinois.edu 
- Kevin Mackie kevindm2@illinois.edu


# Library
```{r, warning=FALSE}
# If you failed to run the Markdown, you may run the following install.packages for the dependencies
#install.packages("corrplot")
#install.packages("kableExtra")
#install.packages('caret', dependencies = TRUE)
#install.packages('e1071', dependencies=TRUE)

library(GGally)
library(faraway)
library(leaps)
library(corpcor)
library(corrplot)
library(ggcorrplot)
library(knitr)
library(kableExtra)
library(caret)
library(outliers)
library(MASS)
library(faraway)
library(ggplot2)
library(ggthemes)
library(lmtest)

```

#Public method

```{r}
ptm = proc.time()
is_debug = TRUE
missing = "missing"
response  = c("SalePrice")

calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

mape = function(actual, pred){
  mean(abs((actual - pred) / actual)) * 100
}

convert_factor_to_numeric = function(variable){
  result = as.numeric(variable)
  result[which(is.na(result))] = 0
  result
}

factor_preprocess = function(variable){
  level = unique(variable)
  numberoflevel = length(level)

  factor(variable, levels = level, labels = seq(1, numberoflevel))
}

start_log = function(){
  if (is_debug){
     ptm = proc.time()
  }
}

end_log = function(){
    if (is_debug){
       print(proc.time() - ptm)
    }
}

validate_data_structure = function(dataset1, dataset2){
  validate_result = TRUE 
  for (i in which(sapply(dataset2, is.factor))) {
     level1 = unique(dataset1[, i])
     level2 = unique(dataset2[, i])
      
          
     if (length(setdiff(level1, level2)) > 0){
         print(level1)
         print(level2)
         validate_result = FALSE
     }
     if (length(setdiff(level2, level1)) > 0){
         print(level2)
         print(level1)
         validate_result = FALSE
     }
  }
  validate_result
}


remove_no_existing_factors = function(test_dataset, base_dataset){
  result_dataset = test_dataset
  base_names = names(base_dataset)
  for (i in which(sapply(test_dataset, is.factor))) {
     test_column_name = names(test_dataset)[i]
     if (test_column_name %in%  base_names){
         train_levels = unique(base_dataset[, test_column_name])
         result_dataset = subset(result_dataset, (result_dataset[,test_column_name] %in% train_levels))
     }
  }
  result_dataset
}

```


```{r, warning=FALSE}
remove_leverage_Observations = function(model, data){
     data[-which(hatvalues(model) > 2 * mean(hatvalues(model))), ]
}

remove_Outliers_Observations = function(model, data){
     data[-which(abs(rstandard(model)) > 2), ]
}

remove_Influence_Observations = function(model, data){
     data[-which(cooks.distance(model) > 4 / length(cooks.distance(model))), ]
}

remove_unusual_observations = function(model, dataset){
    dataset = remove_leverage_Observations(model, dataset)
    dataset = remove_Outliers_Observations(model, dataset)
    dataset = remove_Influence_Observations(model, dataset)
    dataset = drop_only_one_level_factor(dataset)
    dataset
}



build_additive_model = function(dataset){
    model = lm(SalePrice ~ ., data = dataset)
    model
}
```

```{r}
preprocess = function(dataset){
  datasetv1 = dataset
  for (i in which(sapply(dataset, is.numeric))) {
      datasetv1[is.na(dataset[, i]), i] = mean(dataset[, i],  na.rm = TRUE)
  }

  
  # factor preprocess
  datasetv2 = datasetv1
  for (i in which(sapply(datasetv1, is.character))) {
      datasetv2[is.na(datasetv1[, i]), i] = missing
      datasetv2[, i] = as.factor(datasetv2[, i])
  }

  datasetv2
}


drop_only_one_level_factor = function(dataset){
  datasetv1 = dataset
  droplist = c()
  for (i in which(sapply(dataset, is.factor))) {
      level = unique(dataset[, i])
      if ((length(level) <= 1) | ((length(level) == 2) & (missing %in% level))){
          droplist = c(droplist, i)
      }
  }

  for (i in which(sapply(datasetv1, is.numeric))) {
      level = unique(datasetv1[, i])
      if (length(level) <= 1){
          droplist = c(droplist, i)
      }
  }
  if (length(droplist) > 0){
      datasetv1 = datasetv1[ , -droplist]
  }
  datasetv1
}
```



# Introduction
The data, which was found on Kaggle, is a publicly available data set on housing prices in the city of Ames, Iowa that was curated by Dean De Cock of Truman state university.

* https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview
* http://jse.amstat.org/v19n3/decock.pdf

It consists of 1460 observations with one numerical response (house price) and 80 predictors. The predictors are a relatively even mix of numerical and categorical variables.

Here's a brief version of what you'll find in the data description file.

- SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.
- MSSubClass: The building class - # what do 20, 60, 70, etc.... represent?
- MSZoning: The general zoning classification : factors = { C (all), FV, RH, RL, RM }
- LotFrontage: Linear feet of street connected to property
- LotArea: Lot size in square feet
- Street: Type of road access : factors = { Grvl, Pave }
- Alley: Type of alley access : factors = { Grvl, Pave }
- LotShape: General shape of property : factors = { IR1, IR2, IR3, Reg }
- LandContour: Flatness of the property : factors = { Bnk, HLS, Low, Lvl }
- Utilities: Type of utilities available : factors = { AllPub, NoSeWa }
- LotConfig: Lot configuration : factors = { Corner, CulDSac, FR2, FR3, Inside }
- LandSlope: Slope of property : factors = { Gtl, Mod, Sev }
- Neighborhood: Physical locations within Ames city limits : factors = { Blmngtn, Blueste, ...}
- Condition1: Proximity to main road or railroad : factors = { Artery, Feedr, Norm, PosA, ...}
- Condition2: Proximity to main road or railroad (if a second is present) : factors = { Artery, Feedr, ... }
- BldgType: Type of dwelling : factors = { 1Fam, 2fmCon, Duplex, Twnhs, TwnhsE }
- HouseStyle: Style of dwelling : factors = { 1.5Fin, 1.5Unf, 1Story, 2.5Fin, 2.5Unf, 2Story, SFoyer, SLvl }
- OverallQual: Overall material and finish quality
- OverallCond: Overall condition rating
- YearBuilt: Original construction date
- YearRemodAdd: Remodel date
- RoofStyle: Type of roof : factors = { Flat, Gable, Gambrel, Hip, Mansard, Shed }
- RoofMatl: Roof material : factors = { ClyTile, CompShg, Membran, Metal, Roll, Tar&Grv, WdShake, WdShngl }
- Exterior1st: Exterior covering on house : factors = { AsbShng, AsphShn, BrkComm, BrkFace, CBlock, ... }
- Exterior2nd: Exterior covering on house (if more than one material) : factors = { AsbShng, AsphShn, ... }
- MasVnrType: Masonry veneer type : factors = { BrkCmn, BrkFace, None, Stone }
- MasVnrArea: Masonry veneer area in square feet
- ExterQual: Exterior material quality : factors = { Ex, Fa, Gd, TA }
- ExterCond: Present condition of the material on the exterior : factors = { Ex, Fa, Gd, Po, TA }
- Foundation: Type of foundation : factors = { BrkTil, CBlock, PConc, Slab, Stone, Wood }
- BsmtQual: Height of the basement : factors = { Ex, Fa, Gd, TA }
- BsmtCond: General condition of the basement : factors = { Fa, Gd, Po, TA }
- BsmtExposure: Walkout or garden level basement walls : factors = { Av, Gd, Mn, No }
- BsmtFinType1: Quality of basement finished area : factors = { ALQ, BLQ, GLQ, LwQ, Rec, Unf }
- BsmtFinSF1: Type 1 finished square feet
- BsmtFinType2: Quality of second finished area (if present) : factors = { ALQ, BLQ, GLQ, LwQ, Rec, Unf }
- BsmtFinSF2: Type 2 finished square feet
- BsmtUnfSF: Unfinished square feet of basement area
- TotalBsmtSF: Total square feet of basement area
- Heating: Type of heating : factors = { Floor, GasA, GasW, Grav, OthW, Wall }
- HeatingQC: Heating quality and condition : factors = { Ex, Fa, Gd, Po, TA }
- CentralAir: Central air conditioning : factors = { N, Y }
- Electrical: Electrical system : factors = { FuseA, FuseF, FuseP, Mix, SBrkr }
- 1stFlrSF: First Floor square feet
- 2ndFlrSF: Second floor square feet
- LowQualFinSF: Low quality finished square feet (all floors)
- GrLivArea: Above grade (ground) living area square feet
- BsmtFullBath: Basement full bathrooms
- BsmtHalfBath: Basement half bathrooms
- FullBath: Full bathrooms above grade
- HalfBath: Half baths above grade
- Bedroom: Number of bedrooms above basement level
- Kitchen: Number of kitchens
- KitchenQual: Kitchen quality : factors = { Ex, Fa, Gd, TA }
- TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)
- Functional: Home functionality rating : factors = { Maj1, Maj2, Min1, Min2, Mod, Sev, Typ }
- Fireplaces: Number of fireplaces
- FireplaceQu: Fireplace quality : factors = { Ex, Fa, Gd, Po, TA }
- GarageType: Garage location : factors = { 2Types, Attchd, Basment, BuiltIn, CarPort, Detchd }
- GarageYrBlt: Year garage was built
- GarageFinish: Interior finish of the garage : factors = { Fin, RFn, Unf }
- GarageCars: Size of garage in car capacity
- GarageArea: Size of garage in square feet
- GarageQual: Garage quality : factors = { Ex, Fa, Gd, Po, TA }
- GarageCond: Garage condition : factors = { Ex, Fa, Gd, Po, TA }
- PavedDrive: Paved driveway : factors = { N, P, Y }
- WoodDeckSF: Wood deck area in square feet
- OpenPorchSF: Open porch area in square feet
- EnclosedPorch: Enclosed porch area in square feet
- 3SsnPorch: Three season porch area in square feet
- ScreenPorch: Screen porch area in square feet
- PoolArea: Pool area in square feet
- PoolQC: Pool quality : factors = { Ex, Fa, Gd }
- Fence: Fence quality : factors = { GdPrv, GdWo, MnPrv, MnWw }
- MiscFeature: Miscellaneous feature not covered in other categories : factors = { Gar2, Othr, Shed, TenC }
- MiscVal: $Value of miscellaneous feature
- MoSold: Month Sold
- YrSold: Year Sold
- SaleType: Type of sale : factors = { COD, Con, ConLD, ConLI, ConLw, CWD, New, Oth, WD }
- SaleCondition: Condition of sale : factors = { Abnorml, AdjLand, Alloca, Family, Normal, Partial }

For this project our goal will be to attempt to find a "good model" (see below) using a variety of methods that both performs well and is good for explanatory purposes.

A "good model" should:

* Have a Mean Absolute Percentage Error less than 15%, and preferably 10% or lower
* Adhere to LINE assumptions for linear regression i.e. has constant variance and demonstrates normality
* Has no destabilizing collinearity among the predictors i.e. no VIF >= 5



# Methods
This section should contain any information about data preparation that is performed to the original data before modelling. Then you will apply methods seen in class, which may include some of the following but are not limited to:

- Multiple linear regression
- Dummy variables
- Interaction
- Residual diagnostics
- Outlier diagnostics
- Transformations
- Polynomial regression
- Model selection
Your task is not to use as many methods as possible. Your task is to use appropriate methods to find a good model that can correctly answer a question about the dataset, and then to communicate your result effectively.


## Exploratory Data Analysis



> Read the train.csv file, and run the preprocess, what preprocess doing is:
- If the variable is numeric and is na, then use mean to replace;
- Replace the na factor value to "missing", this will make model process easier;

```{r}
train = read.csv("train.csv", stringsAsFactors=FALSE)[, -1]
house_prices_train = preprocess(train)

```



> We will run collinearity Test

##Correlation tests
```{r}
correlation_tests = function(data){
   drops <- c("SalePrice")
   X = data[ , !(names(data) %in% drops)]
   round(cor(X, use = "everything"), 4)
}

correlation_plot = function(corr_data){
   corrplot(corr_data, type = "upper", tl.pos = "td",
         method = "circle", tl.cex = 0.5, tl.col = 'black',
         diag = FALSE)
}

correlation_table = function(corr_data){
   kable(corr_data, "html") %>%
     kable_styling(bootstrap_options = "striped", font_size = 9) %>%
     scroll_box(width = "100%", height = "500px")
}

correlation_list = function(corr_data){
    corr_data[which(corr_data > 0.8)]
}


X_numeric = house_prices_train[sapply(house_prices_train, is.numeric)]
correlation_test_result = correlation_tests(X_numeric)
correlation_plot(correlation_test_result)
correlation_table(correlation_test_result)
```


> We found some predictors have suspect correlated, we will do the  Variance Inflation Factor(VIF) test laster.
```{r}
correlation_list(correlation_test_result)
```






>First of all, We will build an additive model and then we will remove unusual observations by checking leverage, outliers and influence.

```{r}
additive_model = build_additive_model(house_prices_train)
additive_model_data = remove_unusual_observations(additive_model, house_prices_train)
additive_model = build_additive_model(additive_model_data)

```

> We will do VIF test and then remove the predictors(VIF value greater than 5).

```{r}
(vifs = vif(additive_model)[which(vif(additive_model) > 5)])
```


>Build a new model by removing the predictors which VIF value greater than 5.

```{r}
build_dynamic_model = function(outcome, variables, data){
   f= as.formula(paste(outcome, paste(variables, collapse=" + "), sep=" ~ ")) 
   model = lm(f ,data) 
   model
}

# Dynamically build the model remove all the predictors which VIF value greater than 5
allpredictors = names(house_prices_train)
predictors = setdiff(allpredictors,  names(vifs)) 
predictors = setdiff(predictors, response) 
additive_modified_model = build_dynamic_model(response, predictors, house_prices_train)

additive_modified_model_data = remove_unusual_observations(additive_modified_model, house_prices_train)
allpredictors = names(additive_modified_model_data)
predictors = setdiff(allpredictors,  names(vifs)) 
predictors = setdiff(predictors, response) 
additive_modified_model = build_dynamic_model(response, predictors, additive_modified_model_data)

```


>AIC backward to select the model
```{r}
build_model_by_AIC_Backward = function(data){
   start_log()
   start_model = lm(SalePrice ~ ., data)
   aic_backward_model = step(start_model, trace = 0)
   end_log()
   aic_backward_model
}
aic_backward_model = build_model_by_AIC_Backward(house_prices_train)

#Result:
## lm(formula = SalePrice ~ MSZoning + LotFrontage + LotArea + Street + 
##     LandContour + Utilities + LotConfig + LandSlope + Neighborhood + 
##     Condition1 + Condition2 + BldgType + HouseStyle + OverallCond + 
##     YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + MasVnrType + 
##     ExterQual + BsmtQual + BsmtExposure + BsmtFinType1 + HeatingQC + 
##     BedroomAbvGr + KitchenQual + FireplaceQu + GarageFinish + 
##     GarageQual + GarageCond + PoolQC + SaleType, data = data)
```


>Logit response transformer model.
```{r}
bic_backward_response_transformer_model = lm(log(SalePrice) ~ LotArea + Neighborhood + BldgType + OverallCond + YearRemodAdd + RoofMatl + 
      ExterQual + BsmtQual + BsmtExposure + BedroomAbvGr + KitchenQual + FireplaceQu + GarageFinish + PoolQC, house_prices_train)

aic_backward_response_transformer_model = lm(log(SalePrice) ~ MSZoning + LotFrontage + LotArea + Street + LandContour + Utilities +
      LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallCond + YearRemodAdd + RoofStyle +
      RoofMatl + Exterior1st + MasVnrType + ExterQual + BsmtQual + BsmtExposure + BsmtFinType1 + HeatingQC + BedroomAbvGr + KitchenQual + 
      FireplaceQu + GarageFinish + GarageQual + GarageCond + PoolQC + SaleType, house_prices_train)
```



> Stepwise Search to select the model.
```{r}
build_model_from_stepwise_Search = function(data){
  allpredictors = names(data)
  scope_string = as.formula(paste(response, paste(allpredictors, collapse=" + "), sep=" ~ ")) 
  start_model = lm(log(SalePrice) ~ 1, data)   
  n = nrow(data)
  model = step(start_model, scope = scope_string, direction = "both", k= log(n), trace = 0)
  model   
}

stepwise_Search_model = build_model_from_stepwise_Search(house_prices_train)
```


> Ploy Predictor transformation Model
```{r}
poly_model = lm(log(SalePrice) ~ OverallQual + Neighborhood + TotRmsAbvGrd + GarageArea + BsmtFinSF1 + 
                    RoofMatl + OverallCond + X1stFlrSF + X2ndFlrSF + YearBuilt + 
                    Condition2 + SaleCondition + BsmtExposure + KitchenAbvGr +  LotArea + 
                    KitchenQual + ScreenPorch + Street +  MSSubClass + PoolQC + 
                    BsmtFinSF2 + BsmtUnfSF + PoolArea + I(LotArea^2) +  I(YearBuilt^2)+ I(GarageArea^2), house_prices_train)

addi_model = lm(SalePrice ~ OverallQual + Neighborhood + TotRmsAbvGrd + GarageArea + BsmtFinSF1 + 
                    RoofMatl + OverallCond + X1stFlrSF + X2ndFlrSF + YearBuilt + 
                    Condition2 + SaleCondition + BsmtExposure + KitchenAbvGr +  LotArea + 
                    KitchenQual + ScreenPorch + Street +  MSSubClass + PoolQC + 
                    BsmtFinSF2 + BsmtUnfSF + PoolArea + I(LotArea^2) +  I(YearBuilt^2)+ I(GarageArea^2), house_prices_train)

```

> BIC Selected model
```{r}
build_model_by_BIC_Backward = function(data){
   start_log()
   n = nrow(data)
   start_model = lm(SalePrice ~ ., data)
   model = step(start_model, k = log(n), trace = 0)
   end_log()
   model
}
bic_backward_model = build_model_by_BIC_Backward(house_prices_train)

## Result:
## lm(formula = SalePrice ~ LotArea + Neighborhood + BldgType + 
##     OverallCond + YearRemodAdd + RoofMatl + ExterQual + BsmtQual + 
##     BsmtExposure + BedroomAbvGr + KitchenQual + FireplaceQu + 
##     GarageFinish + PoolQC, data = data)



bic_backward_model = lm(log(SalePrice) ~ OverallQual + Neighborhood + TotRmsAbvGrd + GarageArea + BsmtFinSF1 + 
                    RoofMatl + OverallCond + X1stFlrSF + X2ndFlrSF + YearBuilt + 
                    Condition2 + SaleCondition + BsmtExposure + KitchenAbvGr +  LotArea + 
                    KitchenQual + ScreenPorch + Street +  MSSubClass + PoolQC + 
                    BsmtFinSF2 + BsmtUnfSF + PoolArea, house_prices_train)



Bic_model = lm(SalePrice ~ MSSubClass + LotArea + Street + Neighborhood + Condition2 + OverallQual + 
    OverallCond + YearBuilt + RoofMatl + MasVnrArea + ExterQual + BsmtQual + BsmtExposure + BsmtFinSF2 + 
    BsmtUnfSF + X1stFlrSF + X2ndFlrSF + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + 
    GarageArea + ScreenPorch + PoolArea + PoolQC + SaleCondition, data = house_prices_train)

Bic_model_data = remove_unusual_observations(Bic_model, house_prices_train)

start_model = lm(SalePrice ~ ., Bic_model_data)
Bic_modified_model = step(start_model, k = log(nrow(Bic_model_data)), trace = 0)

```


> Box-Cox Response Tranformation
```{r}
boxcox(Bic_modified_model, plotit = TRUE)

Bic_boxcox_model = lm((((SalePrice ^ 0.5) - 1) / 0.5) ~ LotArea + Neighborhood + BldgType + OverallQual + OverallCond + YearBuilt + MasVnrArea + ExterQual + BsmtQual + BsmtExposure + BsmtFinSF1 +                      BsmtFinSF2 + BsmtUnfSF + X1stFlrSF + X2ndFlrSF + BedroomAbvGr + KitchenQual + Functional + GarageCars + SaleCondition, data = Bic_model_data)


boxcox(bic_backward_response_transformer_model, plotit = TRUE)
addi_boxcox_model = lm((((SalePrice ^ 0.3) - 1) / 0.3) ~ OverallQual + Neighborhood + TotRmsAbvGrd + GarageArea + BsmtFinSF1 + 
                    RoofMatl + OverallCond + X1stFlrSF + X2ndFlrSF + YearBuilt + 
                    Condition2 + SaleCondition + BsmtExposure + KitchenAbvGr +  LotArea + 
                    KitchenQual + ScreenPorch + Street +  MSSubClass + PoolQC + 
                    BsmtFinSF2 + BsmtUnfSF + PoolArea + I(LotArea^2) +  I(YearBuilt^2)+ I(GarageArea^2), house_prices_train)

boxcox(addi_model, plotit = TRUE)
poly_boxcox_model = lm(((log(SalePrice)^4.4 - 1) / 4.4) ~ OverallQual + Neighborhood + TotRmsAbvGrd + GarageArea + BsmtFinSF1 + 
                    RoofMatl + OverallCond + X1stFlrSF + X2ndFlrSF + YearBuilt + 
                    Condition2 + SaleCondition + BsmtExposure + KitchenAbvGr +  LotArea + 
                    KitchenQual + ScreenPorch + Street +  MSSubClass + PoolQC + 
                    BsmtFinSF2 + BsmtUnfSF + PoolArea + I(LotArea^2) +  I(YearBuilt^2)+ I(GarageArea^2), house_prices_train)
                    
```


> Finally we build more than 10 models,we will check which one is the best one.
```{r}
model_list = list(list(model = additive_model, main = "Additive Model", 
                         shapirotestdata = resid(additive_model)),
                  list(model = additive_modified_model, main = "Additive Modified Model",
                         shapirotestdata = resid(additive_modified_model)),
                  list(model = aic_backward_model, main = "AIC Backward Selected Model", 
                         shapirotestdata = resid(aic_backward_model)),
                  list(model = bic_backward_model, main = "BIC Backward Selected Model", 
                         shapirotestdata = resid(bic_backward_model)),
                  list(model = bic_backward_response_transformer_model, main = "BIC Response Transformer Model", 
                         shapirotestdata = predict(bic_backward_response_transformer_model, newdata = house_prices_train)),
                  list(model = aic_backward_response_transformer_model, main = "AIC Response Transformer Model",
                         shapirotestdata = predict(aic_backward_response_transformer_model, newdata = house_prices_train)),
                  list(model = stepwise_Search_model, main = "Stepwise Search Model", 
                         shapirotestdata = predict(stepwise_Search_model, newdata = house_prices_train)),
                  list(model = poly_model, main = "Poly Predictor transformer", 
                         shapirotestdata = predict(poly_model, newdata = house_prices_train)),
                  list(model = addi_model, main = "Additive Predictor transformer", 
                         shapirotestdata = resid(addi_model)),
                  list(model = Bic_boxcox_model, main = "Bic boxcox Model", 
                         shapirotestdata = predict(Bic_boxcox_model, newdata = Bic_model_data)),
                  list(model = addi_boxcox_model, main = "boxcox model",
                         shapirotestdata = predict(addi_boxcox_model, newdata = house_prices_train)),
                  list(model = poly_boxcox_model, main = "Poly boxcox model",
                         shapirotestdata = predict(poly_boxcox_model, newdata = house_prices_train))
                  )
                                  

```


> We will do some testing for those models by the following code:

```{r, warning = FALSE}
fit_model_test = function(models){
   for(model in models){
      model_plot(model)
   }

   model_diagnostics(models)
}

model_model_diagnostics_table = function(diag_data){
     #kable(diag_data) %>%
     #   kable_styling(full_width = F) 

     kable(diag_data) %>%
       kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

}

model_plot = function(model){
      #par(mfrow = c(1, 2))
      #fitted_versus_residuals_plot(model)
      #QQ_plot(model)
      par(mfrow = c(2, 2))
      plot(model$model, main = model$main)
}

model_diagnostics = function(models){
   numberofmodel = length(models)
   modelname = rep(" ", numberofmodel)
   shappiro = rep(0, numberofmodel)
   loocvrmse = rep(0, numberofmodel)
   aicvalue = rep(0, numberofmodel)
   bicvalue = rep(0, numberofmodel)
   bptestvalue = rep(0, numberofmodel)
   rsquared = rep(0, numberofmodel)
   adjrsquared = rep(0, numberofmodel)
   i = 1
   for(model in models){
      modelname[i] = model$main    
      shappiro[i] = shapiro.test(model$shapirotestdata)$p.value
      loocvrmse[i] = calc_loocv_rmse(model$model)
      aicvalue[i] = extractAIC(model$model)[2]
      bicvalue[i] = extractAIC(model$model, k = log(length(resid(model$model))))[2]
      bptestvalue[i] = bptest(model$model)$p.value
      rsquared[i] = summary(model$model)$r.squared
      adjrsquared[i] = summary(model$model)$adj.r.squared
      i = i + 1
   }      
   
   result = data.frame(model = modelname, shapiro_test = format(shappiro, scientific=T), LOOCV_MSE =loocvrmse, 
                          AIC = aicvalue, BIC = bicvalue, adj.r.quared=adjrsquared, bptest = bptestvalue, r.quared=rsquared)   
   model_model_diagnostics_table(result)
}

```



# Results

> The following are the models diagnostics result:

```{r}

fit_model_test(model_list)
```


```{r}
final_model = Bic_boxcox_model
final_model_train_data = Bic_model_data
```


> The "BIC boxcox Model" is the best one in the model test table, there are couple result as following:

- Is the normality assumption violated in the log-linear model?

   The normality assumption is still violated in the log-linear model. The p-value < 0.01 for both the tests.The model adheres to Linearity if the fitted plot has a close to horizontal line. This model does not have a horizontal line. The transformed model appears to have improved from the base linear-linear model by Q-Q plot.
   
- We have more than `r summary(final_model)$r.squared * 100`% of the observed variation can be explained by the model's inputs.





# Discussion

> The next, We will do the prediction by using the test data to see how good is the final model.

```{r}
test_vs_train_plot = function(model, train, test, predict_result){
   trn_df = data.frame(house_price = fitted(model), year_built = train[, "YearBuilt"] )
   test_df = data.frame(house_price = predict_result, year_built= test[ , "YearBuilt"])
   
   ggplot(data = trn_df, aes(x = year_built, y = house_price, colour = 'Train')) + 
      geom_line() +  
      geom_line(data = test_df, aes(x=year_built, y=house_price, colour = 'Test'), show.legend = FALSE) + 
      labs(x = "Year Build", y = "House Price", title = "Train vs Test prediction Plot") +
      theme(plot.title = element_text(hjust = 0.5)) +
      scale_color_discrete(name = "Legend", labels = c("Train", "Test")) +
      scale_color_manual(values=c("red", "blue"))
  
}

```


```{r}
test_data = read.csv("test.csv", stringsAsFactors = FALSE)[, -1]
house_prices_test_data = preprocess(test_data)
house_prices_test_data = remove_unusual_observations(final_model, house_prices_test_data)
house_prices_test_data = remove_no_existing_factors(house_prices_test_data, final_model_train_data)
house_prices_test_data = drop_only_one_level_factor(house_prices_test_data)
predict_house_price =  predict(final_model, newdata = house_prices_test_data, na.action = "na.exclude")
test_vs_train_plot(final_model, final_model_train_data, house_prices_test_data, predict_house_price)
```

> The prediction plot looks good by using test data to validate, the model is good for prediction, because normality assumption is still violated in the linear model by all the models, the final model is the small size model,
and linear models are rather interpretable to begin with, out current models aren't very useful for explaining the relationship.


# Appendix
> We will try an automatic method to generate the Box-Cox parameter, and then we will use build a new BOX-Cox model with the final model by using this new parameter.

```{r}
boxcoxbycaret = BoxCoxTrans(Bic_model_data$SalePrice)                    
summary(boxcoxbycaret)
boxcoxbycaret_model = lm((SalePrice - 1) ~ LotArea + Neighborhood + BldgType + OverallQual + OverallCond + YearBuilt + MasVnrArea + ExterQual + BsmtQual + 
     BsmtExposure + BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF + X1stFlrSF + X2ndFlrSF + BedroomAbvGr + KitchenQual + Functional + GarageCars + SaleCondition, data = Bic_model_data)

model_list = list(list(model = final_model, main = "Final Model", shapirotestdata = predict(final_model, newdata = Bic_model_data)),
                  list(model = boxcoxbycaret_model, main = "Box-Cox by Caret Model", shapirotestdata = predict(boxcoxbycaret_model, newdata = Bic_model_data)) )

model_diagnostics(model_list)

```

> The Final Model is still better than the new model.



